{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 확률론적 선형회귀모형 복습\n",
    "- 1) 선형정규분포 가정\n",
    "    - y값이 정규분포인데, 정규분포의 중앙값 기댓값이 x에 의해 결정된다\n",
    "    - 잡음은 0을 기댓값으로 하는 정규분포다\n",
    "    - x, y 중 그 어느것도 그 자체로 정규분포일 필요는 없다.\n",
    "    - x는 확률변수 아니다, 주어진 상수값. y가 확률변수\n",
    "- 2) 외생성 가정\n",
    "    - 디스터번스의 기댓값은 독립변수 x의 크기에 상관없이 항상 0이라고 가정한다.\n",
    "- 3) 조건부 독립 가정\n",
    "    - i번째 표본 잡음 입실론과 j번째 표본 잡음 입실론의 공분산 값이 x와 상관없이 항상 0이라고 가정\n",
    "    - 이는 서로 독립이라는 가정과 같다\n",
    "- 4) 등분산성 가정\n",
    "    - 첫번째 데이터에 대한 입실론의 크기나 두번째 데이터에 대한 입실론의 크기나 항상 똑같다\n",
    "    \n",
    "#### 최대 가능도 방법을 사용한 선형회귀 분석\n",
    "- w 값은 OLS로 구했을 때와 똑같은 수식이 나온다\n",
    "    - OLS에서는 잔차 제곱합을 최소화하는(최소자승법) 방법 이용\n",
    "    - 최대가능도 방법에서는 가능도를 최대화하는 방법 이용\n",
    "- cf) OLS(Ordinary Least Squares)\n",
    "- WLS(Weighted LS): 중요한 데이터라서 여기에 에러는 적어야 하고, 덜 중요한 데이터라서 에러는 많아도 되고 식으로 각각의 샘플에 대해 가중치를 줄 수 있게 된다. 가중치 주게 되는 방식으로 계산하는 방법론도 있는데 이 때 OLS가 아니라 WLS를 쓰게 된다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-19T02:03:33.829843Z",
     "start_time": "2020-05-19T02:03:33.826301Z"
    }
   },
   "source": [
    "#### 결론: OLS로 했을 떄는 최대가능도 방법으로 했을 때와 답이 똑같다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-19T02:19:06.623406Z",
     "start_time": "2020-05-19T02:19:06.615453Z"
    }
   },
   "source": [
    "### 단일계수 t-검정\n",
    "- 계수가 너무 복잡하면 회귀분석 식 만들 때도, 고객에게 설명할 때도 불편할 수 있다.\n",
    "- RegressionResults 클래스 객체는 t-test를 위한 t_test 메서드를 제공한다.\n",
    "- 이 메서드를 사용하면 계수 값이 0이 아닌 경우도 테스트할 수 있다.\n",
    "- 예를 들어 위 예제에서 귀무가설을 다음처럼 놓고 H0 : w1 = 40(원래는 42.땡땡) x1에 대한 계수값 w1을 40으로 해도 되는지 테스트할 수도 있다\n",
    "- print(result.t_test(\"X1 = 40\"))\n",
    "- 이 검정 결과에 따르면 x1에 대한 계수를 40으로 한다고 해도 문제가 없음을 알 수 있다.\n",
    "\n",
    "- 이 방법은 두 독립변수의 계수값을 비교할 때도 쓸 수 있다. 범주형 독립변수의 범주값이 가지는 유의성을 판단하는데 유용하다. 예를 들어 월평균 기온을 나타내는 nottem 데이터에서 1월과 2월의 기온이 실질적으로 같은지를 알아볼 때도 사용할 수 있다.\n",
    "- print(result_nottem.t_test(\"C(month)[01] = C(month)[02]\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-19T02:26:34.688903Z",
     "start_time": "2020-05-19T02:26:34.678398Z"
    }
   },
   "source": [
    "### 회귀분석 F-검정\n",
    "- 개별 개수가 아닌 전체 회귀 계수가 모두 의미가 있는지 확인하는 경우에는 다음과 같은 귀무가설을 생각할 수 있다\n",
    "- H0 : w0=w1=w2=...=wK-1 = 0\n",
    "- 이는 전체 독립변수 중 어느 것도 의미를 가진 것이 없다는 뜻. 대부분의 경우 이 귀무가설은 기각됨\n",
    "- 다만 유의 확률이 얼마나 작은가에 따라서 기각되는 정도가 달라진다. 유의확률이 작으면 작을수록 더 강력하게 기각된 것이므로 더 의미가 있는 모형이라고 할 수 있다\n",
    "- 따라서 여러 모형의 유의확률을 비교해 어느 모형이 더 성능이 좋은가를 비교할 때 이 유의확률을 사용한다.\n",
    "- 이러한 검정을 Loss-of-Fit 검정 또는 회귀분석 F-검정(regression F-test)이라고 한다\n",
    "- 결과 보고서에서 F-statistic 라고 표시된 400.3이라는 값이 회귀분석 F-검정의 검정통계량이고 Prob(F-statistic)로 표시된 2.21e-36라는 값은 유의확률을 뜻한다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-19T02:29:41.125790Z",
     "start_time": "2020-05-19T02:29:41.121639Z"
    }
   },
   "source": [
    "#### 회귀분석 F-검정은 성능 분석의 척도로 사용된다. p value가 작으면 작을수록 더 좋은 모델이다!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-19T02:36:26.882639Z",
     "start_time": "2020-05-19T02:36:26.873569Z"
    }
   },
   "source": [
    "#### 회귀분석 보고서 밑부분의 omnibus는 정규성 검정인 옴니버스 검정을 말한다. 정규성 검정은 확률분포의 모양이 정규분포인지 아닌지를 확인한다.\n",
    "- 옴니버스 테스트와, 옴니버스 테스트의 p value: Prob(Omnibus)\n",
    "- 여기서는 잔차가 정규분포인지를 따지는 것. 우리 모델에 따르면 잔차는 정규분포여야 함. 아니면 잘못된 것\n",
    "- 혹시라도 정규성분포이냐 아니냐를 따질 때 Skew, Kurtosis를 보고 판단할 수 있기 떄문에. 여기서 스큐와 커토시스도 잔차의 스큐와 커토시스임\n",
    "\n",
    "#### Durbin-Watson은 각각의 샘플들이 상관관계가 있는가 하는 상관 가정을 체크한건데 테스트 검정량만 있고 p-value가 없기 때문에 별 쓸모 없음\n",
    "#### 컨디션 넘버\n",
    "- 다중공선성이나 스케일링이 안 된 것을 체크하기 위한 수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.3 레버리지와 아웃라이어"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-19T02:39:40.726532Z",
     "start_time": "2020-05-19T02:39:40.722740Z"
    }
   },
   "outputs": [],
   "source": [
    "### 1) 레버리지\n",
    "- 개별적인 데이터 표본 하나하나가 회귀분석 결과에 미치는 영향력은 레버리지 분석이나 아웃라이어 분석을 통해 알 수 있다\n",
    "    - 앞에서는 세로축으로 종류별로 의미가 있는지 없는지 확인\n",
    "    - 여기서는 가로축으로 데이터별로 의미가 있는지 없는지 확인\n",
    "- 레버리지(leverage)는 실제 종속변수값 y가 예측치(predicted target) y hat에 미치는 영향을 나타낸 값\n",
    "    - self-influence, self-sensitivity라고도 한다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-19T02:48:54.547269Z",
     "start_time": "2020-05-19T02:48:54.534948Z"
    }
   },
   "source": [
    "- 가중치 벡터의 결과값을 예측식에 대힙해 y와 y hat의 관계를 다음과 같다는 것을 보였었다\n",
    "- y hat = Hy\n",
    "- 이 행렬 H를 영향도 행렬(influence matrix) 또는 hat 행렬(hat matrix)이라고 한다\n",
    "- 여기서 레버리지는 수학적으로 영향도 행렬의 대각성분 hii로 정의된다. 즉 레버리지는 실제의 결과값 yi의 예측값 yi hat에 미치는 영향, 즉 예측점을 자기 자신의 위치로 끌어당기는 정도를 나타낸 것.\n",
    "- y hat 값 즉 예측치가 정답에 얼마나 가깝게 가게 되는지 결정해준다.\n",
    "- 만약 hii 값이 1이 되고 나머지 성분들이 모두 0이 될 수만 있다면 모든 데이터에 대해 실제 결과값과 예츠값이 일치하게 될 것이다\n",
    "- 하지만 곧 알 수 있듯이 이러한 일은 발생하지 않는다. 레버리지 값은 다음과 같은 특성을 가진다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-19T02:55:41.017408Z",
     "start_time": "2020-05-19T02:55:40.988593Z"
    }
   },
   "source": [
    "1) 레버리지 값 hii는 작은 양수 혹은 0이다. 0과 1 사이의 값을 가진다\n",
    "2) 레버리지의 값(대각선)을 모두 합하면 모형에 사용된 모수의 개수K(우리가 모은 데이터의 종류)와 같다\n",
    "    - 모수에는 상수항도 포함되므로 상수항이 있는 1차원 모형에서는 K=2가 된다\n",
    "- K개밖에 안 되는 값을 N개의 h들이 나눠가져야 한다. 데이터 하나당 h 하나. 모두 1일일 수 없다.\n",
    "- 레버리지의 평균값보다도 크게 나오면 레버리지가 큰 애들이다\n",
    "    - 보통은 평균값의 2~4배보다 레버리지 값이 크면 레버리지가 크다고 얘기한다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-19T03:06:40.041729Z",
     "start_time": "2020-05-19T03:06:40.032432Z"
    }
   },
   "source": [
    "### statsmodels를 이용한 레버리지 계산\n",
    "- 레버리지 값은 RegressionResults 클래스의 get_influence 메서드로 구현할 수 있다\n",
    "- influence = result.get_influence()\n",
    "- hat = influence.hat_matrix_diag\n",
    "- plt.stem(hat)\n",
    "- 어떤 데이터가 레버리지가 큰가? 무리지어 있는 데이터들보다 혼자 떨어져 있는 데이터들의 레버리지가 크다\n",
    "    - 다시 말해 데이터의 영향력이 크다는 것\n",
    "    - 20~30 평대 집 데이터가 많고 100평대 집 데이터가 없으면 100평대 집 데이터 결과는 소수의 데이터가 좌우할 수 있는 것.\n",
    "    - 20~30평대 해당하는 집데이터들은 데이터가 워낙 많기 떄문에 하나하나가 가지는 대표성이 떨어진다. 레버리지도 떨어진다.\n",
    "\n",
    "#### 그 x 근처에서 대표성이 큰 애들이 레버리지가 커진다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-19T04:32:12.571048Z",
     "start_time": "2020-05-19T04:32:12.550965Z"
    }
   },
   "source": [
    " ### 레버리지의 영향\n",
    "- 레버리지가 큰 데이터가 모형에 주는 영향을 보기 위해 이 데이터가 포함된 경우의 모형과 포함되지 않은 경우의 모형을 비교\n",
    "- 레버리지가 큰 데이터는 포함되거나 포함되지 않는가에 따라 모형에 주는 영향이 큰 것을 알 수 있다\n",
    "- 레버리지가 큰 데이터는 함부로 빼거나 넣을 수 없다\n",
    "- 레버리지가 작은 데이터는 빼도 된다\n",
    "- 레버리지가 크더라도 오차(잔차)가 작은 애들은 빼도 큰 영향이 없다.\n",
    "- 결국 레버리지 값이랑 오차 값이 둘 다 큰 애들을 조심해야 한다는 것"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 아웃라이어\n",
    "- 모형에서 설명하고 있는 데이터와 동떨어진 값을 가지는 데이터, 즉 잔차가 큰 데이터를 아웃라이어(outlier)라고 한다.\n",
    "- 그런데 잔차의 크기는 독립변수의 영향을 받으므로 아웃라이어를 찾으려면 이 영향을 제거한 표준화된 잔차를 계산해야 한다\n",
    "    - 오차의 표준편차는 모든 표본에 대해 같지만 개별적인 잔차의 표준편차는 레버리지에 따라 달라지는 것을 알 수 있다\n",
    "    - 잔차를 레버리지와 잔차의 표준편차로 나누어 동일한 표준 편차를 가지도록 스케일링한 것을 표준화 잔차(standardized residual 또는 normalized residual 또는 studentized residual)라고 한다\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-19T04:44:27.657946Z",
     "start_time": "2020-05-19T04:44:27.647524Z"
    }
   },
   "source": [
    "- 잔차 result.resid\n",
    "- 표준화 잔차는 result.resid_pearson 속성에 있다. 보통 표준화 잔차가 2~4보다 크면 아웃라이어로 본다\n",
    "#### 아웃라이어다 아니다는 표준화 잔차를 가지고 비교하면 된다. 대부분의 경우 +-2~4보다 커지면 아웃라이어라고 보면 된다\n",
    "- 사실 아웃라이어는 하나하나 다 찾아봐야 한다.\n",
    "- 입력상 오류가 있어서 아웃라이어가 됐다고 하면 데이터 빼도 된다. 이때 레버리지가 큰지 안 큰지를 보고 심각하게 결정해야\n",
    "- 만약 레버리지가 적으면 안심하고 빼도 되지만 큰 애들은 진짜로 잘 살펴보고 빼야.\n",
    "#### 표준화된 잔차가 큰가 아닌가, 레버리지가 큰가 아닌가 두 가지를 동시에 봐야 한다\u001b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-19T04:48:46.663648Z",
     "start_time": "2020-05-19T04:48:46.653595Z"
    }
   },
   "source": [
    "- 이를 동시에 보는 기준이 있다\n",
    "### Cook's Distance\n",
    "- 표준화 잔차와 레버리지를 곱한 것\n",
    "- 회귀분석에는 잔차의 크기가 큰 데이터가 아웃라이어가 되는데 이 중에서도 주로 관심을 가지는 것은 레버리지와 잔차의 크기가 모두 큰 데이터들이다.\n",
    "- 잔차와 레버리지를 동시에 보기 위한 기준으로는 Cook's Distance가 있다.\n",
    "- 레버리지가 커지거나 잔차의 크기가 커지면 Cook's Distance 값은 커진다\n",
    "- Fox' Outlier Recommendation 은 Cook's Distance가 다음과 같은 기준값보다 클 때 아웃라이어로 판단하자는 것\n",
    "- Di > 4 / (N - K - 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-19T04:50:41.637015Z",
     "start_time": "2020-05-19T04:50:41.629537Z"
    }
   },
   "source": [
    "- 모든 데이터의 레버리지와 잔차를 동시에 보려면 plot_leverage_resid2 명령을 사용\n",
    "    - 이 명령은 x 축으로 표준화 잔차의 제곱을 표시하고 y 축으로 레비러지값을 표시. 데이터 아이디가 표시된 데이터들이 레버리지가 큰 아웃라이어\n",
    "- influence_plot 명령을 사용하면 Cook's Distance를 버블 크가로 표시한다\n",
    "    - sm.graphics.influence_plot(result, plot_alpha=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 아웃라이어 빼면 R-squared (퍼포먼스)가 올라간다. 규칙에 잘 맞는 애들만 모아서 모델링했기 때문에 당연\n",
    "- 그런데 퍼포먼스가 올라갔다고 해서 우리의 최종 목표가 더 잘 달성됐다는 보장은 없다\n",
    "- 이게 잘 달성되려면 우리가 실제로 테스트하려는 데이터에도 아웃라이어가 없어야 한다. 그러면 아웃라이어 빼고 분석한 결과가 더 좋은 결과\n",
    "- 실제 쓰려는 데이터와 가까운 데이터로 분석해야 한다는 것\u001b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.4 분산 분석과 모형 성능\n",
    "- 회귀분석하고 나서 모형이 잘 만들어진 모형이다 아니다 점수를 매겨야 할 떄가 있다\n",
    "- 좋은 모형 보통 오차가 적은 것. 보통 오차의 제곱합이 적으면 좋은 모델 아니냐고 생각\n",
    "- 문제는 상대적 비교가 불가능하다는 것\n",
    "- RSS는 데이터가 많아지면 커지는 값. y 값의 단위가 달라져도 달라지는 값\n",
    "    - 변수의 단위, 즉 스케일이 달라지면 회귀분석과 상관없이 잔차제곱합도 달라진다\n",
    "- 잔차 제곱합(RSS) 자체로 모델을 비교하는 것은 불가능.\n",
    "- 그래서 어떤 기준 값을 이용해 정규화할 필요 있음\n",
    "- 그 정규화하는 방법이 바로 분산 분석(ANOVA, Analysis of Variance).\n",
    "- 종속변수의 분산과 독립변수의 분산 간의 관계를 사용해 선형회귀분석의 성능을 평가하고자 하는 방법.\n",
    "- 분산 분석은 서로 다른 두 개의 선형회귀분석의 성능 비교에 응용할 수 있으며 독립변수가 카테고리 변수인 경우 각 카테고리 값에 따른 영향을 정량적으로 분석하는데도 사용된다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-19T05:12:22.320206Z",
     "start_time": "2020-05-19T05:12:22.311242Z"
    }
   },
   "source": [
    "- TSS(Totla sum of squares) : 종속 변수 y의 분산\n",
    "    - TSS 는 종속변수값의 움직임의 범위를 나타낸다\n",
    "    - 샘플의 개수로 나누지 않았기 떄문에 엄격히 말해서 분산은 아님. 비슷한 개념\n",
    "- ESS(Explained sum of squares) : 회귀분석에 의해 예측한 값 y hat의 분산\n",
    "- RSS(residual sum of squares): 잔차 e의 분산\n",
    "\n",
    "#### TSS는 y값 전체의 움직임의 범위, ESS는 모형에서 나온 예측값의 움직임의 범위, RSS는 잔차의 움직임의 범위, 즉 오차의 크기를 뜻한다고 볼 수 있다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 만약 회귀모형이 상수항을 포함해 올바르게 정의됐다면 잔차의 평균은 0. 즉, 종속변수의 평균과 모형 예측값의 평균은 같다\n",
    "- 그리고 이 분산값들 간에는 다음과 같은 관계가 성립 TSS = ESS + RSS\n",
    "\n",
    "- 위 식이 말하는 바는 다음과 같다\n",
    "    - 모형 예측치의 움직임의 크기(분산)은 종속변수의 움직임의 크기(분산)보다 클 수 없다\n",
    "    - 모형 성능이 좋을수록 모형 예측치의 움직임의 크기는 종속변수의 움직임의 크기와 비슷해진다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-19T05:20:52.216376Z",
     "start_time": "2020-05-19T05:20:51.573959Z"
    }
   },
   "source": [
    "- print(\"TSS = \", result.uncentered_tss)\n",
    "- print(\"ESS = \", result.mse_model)\n",
    "- print(\"RSS = \", result.ssr)\n",
    "- print(\"R squared = \", result.rsquared)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-19T05:41:57.065744Z",
     "start_time": "2020-05-19T05:41:57.043946Z"
    }
   },
   "source": [
    "### 결정계수(Coefficient of Dertermination), R square\n",
    "- 이 관계를 이용하면 결정계수를 정의할 수 있다.R ** 2\n",
    "- 결정계수는 분산 관계식에서 모형의 성능을 나타냄\n",
    "- 오차가 하나도 없는 완벽한 모델일 때 결정계수 값은 1\n",
    "- RSS가 커지면 커질수록 나빠짐. RSS는 TSS만큼 커질 수 있다. 이 때 결정계수 값은 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 분산분석표\n",
    "- 결정계수를 나타날 때 분산분석표와 같이 나타낸다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-19T05:56:23.973311Z",
     "start_time": "2020-05-19T05:56:23.955583Z"
    }
   },
   "source": [
    "### 회귀분석 F-검정과 분산 분석의 관계\n",
    "- 이러한 모양의 표를 사용하는 이유는 분산 분석의 결과를 이용해 회귀 분석 F-검정에 필요한 검정통계량을 구할 수 있기 때문\n",
    "#### 분산분석(ANOVA)표는 RSS, ESS, TSS 값뿐만 아니라 F-test의 결과도 같이 보여주는 것이다라고 생각하면 됨\n",
    "- statsmodles에서는 anova_lm 명령을 사용하면 분산분석표를 출력할 수 있다. 다만 이 명령을 사용하기 위해서는 모형을 from_formula 메서드로 생성해야 한다\n",
    "- anova_lm 명령으로 구한 F 검정통계량과 유의확률은 모형 summary 명령으로 구한 F-statistic 및 Prob(F-statistic)과 일치\n",
    "- sm.stats.anova_lm(result)\n",
    "- 분산분석표에서 X의 sum_sq의 값을 잔차까지 모두 더한 값으로 나눈 값이 R-squared"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 결정 계수와 상관 계수\n",
    "- y와 y hat의 샘플 상관계수 r의 제곱은 결정계수 R square와 같다\n",
    "     - 그래서 이름을 R square로 지은 것"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-19T06:13:18.226806Z",
     "start_time": "2020-05-19T06:13:18.208271Z"
    }
   },
   "source": [
    "### 상수항이 없는 모형의 경우\n",
    "- 모형에서 상수항을 지정하지 않은 경우에는 결정계수의 정의에 사용되는 TSS의 정의가 달라진다\n",
    "- 모형의 결정계수를 비교할 때 상수항이 없는 모형과 상수항이 있는 모형은 직접 비교하면 안 된다\n",
    "    - 공식이 다르기 때문에 비교가 의미가 없어진다.\n",
    "    - 그런데 기본적으로는 상수항이 없는 모델은 쓰면 안 된다. 상수항에 대한 p-value를 확인하기 전까지는\n",
    "    - cf) 상수항이 없을 때 R-squares 값이 좋게 나오는 경우도 있다.\n",
    "    - 상수항 제거 가능한 경우: 해봤는데 상수항에 대한 p-value가 너무 컸을 때, 도메인 지식이 있는데 상수항이 없는 경우가 맞을 때\u001b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-19T06:18:26.956552Z",
     "start_time": "2020-05-19T06:18:26.935043Z"
    }
   },
   "source": [
    "### F 검정을 이용한 모형 비교\n",
    "- F 검정을 이용하면 다음과 같이 포함관계(nesting)에 있는 두 모형의 성능을 비교할 수 있다\n",
    "- 전체 모형(Full Model): y = w0 + w1x1 + w2x2 + w3x3\n",
    "- 축소 모형(Reduced Model): y= w0 + w1x1\n",
    "- 다음과 같은 귀무 가설을 검정하는 것은 위 의 두 모형이 실질적으로 같은 모형이라는 가설을 검정하는 것과 같다\n",
    "- H0 : w2 = w3 = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 나중에 데이터 종류 엄청 많아질 경우에는 일부를 뺴야하는 경우가 생길 수 있다. 다중공선성 같은 경우. 뺄 때 y에 영향을 덜 미치는 것으로 빼야\n",
    "\n",
    "### F 검정을 사용한 변수 중요도 비교\n",
    "- F 검정은 각 독립변수의 중요도를 비교하기 위해 사용할 수 있다. 전체 모형과 각 변수 하나만을 뺀 모형들의 성능을 비교하는 것. 간접적으로 각 독립변수의 영향력을 측정하는 것과 같다.\n",
    "- 이는 싱글 coefficient t-test 한 것과 결과가 똑같다. 다면 여기서는 상관분석 표에서 뒷자리 수까지 세세하게 나와 상대적인 값을 비교하기 좋다\n",
    "    - 서머리 리포트에서 t-test 통계량에 대한 유의확률 값이 소숫점 3자리까지밖에 나오지 않는다\n",
    "    - 그래서 누가 더 작냐, 누가 더 y값에 영향을 미치냐를 구분해주려면 F-검정 이용해야"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 조정 결정 계수, Adj. R-squared\n",
    "- 선형 회귀모형에서 독립 변수가 추가되면 결정 계수의 값은 항상 증가한다.\n",
    "- 우리가 데이터를 하나라도 더 집어넣게 되면 결과는 항상 더 좋다\n",
    "    - sample corelation이 0이 되는 경우는 진짜 상관관계가 없다고 하더라도 존재하지 않는다\n",
    "- 그런데 이런 경우가 진짜로 성능이 좋아진 것이 아니라 과최적화 돼서 그런 경우가 많음\n",
    "    - 데이터만 피팅이 잘 된 것\n",
    "- 데이터가 과최적화가 돼서 잘 된 것인지 진짜로 잘 된 것인지는 나중에 교차검증을 해야 함\n",
    "- 그런데 교차 검증을 하지 않고 대략적으로 데이타 변수 너무 많이 들어가서 잘 나온 게 아닌가 하는 것을 데이터 개수만큼 패널티를 줘서 변수를 많이 넣을수록 점수를 약간 깎는 조정을 해준 값을 실제로 많이 사용한다\n",
    "    - 이렇게 나오는 값이 Adj. R-squared 값\n",
    "    - n값은 데이터 개수 K는 변수의 종류"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 정보량 규준(information criterion)\n",
    "- 성능을 나타낼 때 R-squared 말고도 다른 방법\n",
    "- w 구할 때 최대가능도(우리가 가진 데이터가 나올 수 있는 확률) 추정방법 사용했다. 높으면 높을수록 좋은 것\n",
    "- 결과 리포트에서 Log-Likelihood 값이 제일 높인 확률 값. 음수로 돼 있기 때문에 0으로 다가갈수록 큰 것\n",
    "    - 이걸 비교할 때도 데이터의 종류가 많으면 많을수록 잘 맞는다고 했음 이걸 보정해준 것이 AIC, BIC\n",
    "- 조정 결정 계수와 함께 많이 쓰이는 모형 비교 기준은 최대 우도에 독립 변수의 개수에 대한 손실(penalty)분을 반영하는 방법\n",
    "- 이를 정보량 규준이라고 하며 손실 가중치의 계산법에 따라 AIC(Akaike Information Criterion)와 BIC(Bayesian Information Criterion) 두 가지를 사용\n",
    "    - AIC는 모형과 데이터의 확률 분포 사이의 쿨백-라이블러 수준을 가장 크게하기 위한 시도에서 나왔다.\n",
    "    - BIC는 데이터가 exponential family라는 가정하에 주어진 데이터에서 모형의 라이클리후드(가능도)를 측정하기 위한 값에서 유도됐다.\n",
    "    - 둘 다 값이 작을수록 올바른 모형에 가깝다.\n",
    "    - 둘 다 뒤에 패널티 K값을 더해준다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-19T06:56:36.798409Z",
     "start_time": "2020-05-19T06:56:36.787872Z"
    }
   },
   "source": [
    "### summary\n",
    "- R-squared(결정 계수)는 0과 1사이의 값. 1에 가까울 수록 좋다. \n",
    "- Adj. R-squared(조정 결정 계수)는 데이터 개수만큼 패널티를 준 것\n",
    "- F-statistic : 결정 계수에 대한 F 검정 통계량\n",
    "- Prob(F-statistc): F 검정 통계량에 대한 유의 확률\n",
    "- Log-likelihodd(로그 가능도): 최대 가능도 방법을 이용 했을 때의 결과. 클수록 좋음\n",
    "- AIC, BIC: 로그 가능도에 독립변수의 개수에 대한 손실분을 반영했을 때의 결과. 낮을수록 좋다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 이제 실무에 관련된 내용\n",
    "- 내가 쓰는 모델이 제대로된 모델인지 아닌지 진단하고 제대로된 모형으로 바꾸는 과정에 대해\n",
    "\n",
    "### 6.1 모형 진단과 수정\n",
    "- 회귀분석 결과의 진단(diagnosis)란 회귀분석에 사용된 데이터가 회귀분석에 사용된 모형 가정을 제대로 만족하고 있는지를 확인하는 과정이다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 잔차 정규성\n",
    "- 데이터가 모형 가정을 만족하면 분석결과로 나온 잔차는 정규분포를 따라야 한다\n",
    "- 그렇지 않으면 뭔가 모델이 잘못돼 있을 가능성이 있는 것.\n",
    "- 수정에 반드시 법칙이 있는 것은 아냐. 하다보면 노하우 생겨. trial error 해보는 수밖에"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-19T07:31:54.195855Z",
     "start_time": "2020-05-19T07:31:54.188530Z"
    }
   },
   "source": [
    "#### 잔차가 이상하게 나왔다\n",
    "- 1) 데이터가 비선형이냐 아니냐를 의심해봐야\n",
    "- 2) x 값의 residual을 살펴봐야\n",
    "    - 잔차는 회귀분석으로 예상하고 남은 찌꺼기\n",
    "    - 회귀 분석이 제대로 됐으면 더 이상 예측이 안 돼야 한다\n",
    "    - 그런데 비선형적인 경우에 남아 있는 경우가 있다. 이럴 땐 x**2 형태로 데이터를 변형해서 자꾸 추가해줘야 한다.\n",
    "- 3) 4번째 가정, 모든 샘플에 대해 입실론이 똑같아야 한다에 맞지 않을 때는 y에 로그를 취하면 된다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-19T07:40:44.907216Z",
     "start_time": "2020-05-19T07:40:44.770759Z"
    }
   },
   "source": [
    "### 자기 상관 계수\n",
    "- 선형회귀모형에서는 오차(disturbance)들이 서로 (모수-조건부) 독립이라고 가정하고 있다.\n",
    "- 따라서 잔차(residual)도 서로 독립이어야 한다. 만약 서로 독립이 아니라면 선형회귀 모형이 아닌 ARMA 모형 등의 시계열 모형을 사용해야 한다\n",
    "- 오차가 독립인지 검정하는 방법은 잔차를 시계열로 가정해 자기상관계수를 구하는 것이다.\n",
    "- 만약 독립이라면 시차(lag)가 0인 경우를 제외하고는 자기상관계수 pi가 0이어야 한다. 이를 검사하는 검증으로는 다음과 같은 것들이 있다\n",
    "    - Box-Pierce 검정\n",
    "    - Ljung-Box 검정\n",
    "    - Durbin-watson 검정\n",
    "- y1, y2, y3 간에 상관관계가 있으면 시계열 모형을 갖다가 써야 한다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-19T07:44:36.945706Z",
     "start_time": "2020-05-19T07:44:36.936605Z"
    }
   },
   "source": [
    "# 비선형 변형\n",
    "- 만약 독립변수와 종속변수간의 관계가 비선형이면 이 관계를 선형으로 바꿀 수 있도록 독립변수를 비선형 변환할 수 있다.\n",
    "    - x,y에 로그를 취하거나\n",
    "    - 휘어졌으니 2차항을 적용시키는 것도 방법\n",
    "    - 뭐가 정답이라고 주어지는 것은 없음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 범주형을 사용한 비선형성\n",
    "- 독립변수의 비선형성을 포착하는 또 다른 방법 중 하나는 강제로 범주형 값으로 만드는 것\n",
    "- 범주형 값이 되면서 독립변수의 오차가 생기지만 이로 인한 오차보다 비선형성으로 얻을 수 있는 이익이 클 수도 있다\n",
    "- 너무 비선형성이 심하면 카테고리 값으로 바꿔서 표시하는 일종의 트릭을 쓸수도 있음\n",
    "    - np.round(df_boston.RM)를 이용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-19T08:24:42.639271Z",
     "start_time": "2020-05-19T08:24:42.629396Z"
    }
   },
   "source": [
    "### 시간 독립변수의 변형\n",
    "- 독립변수가 시간인 경우에는 특정 시점에서 경과된 시간값으로 변형해야 한다. 이를 에포크?라고 한다\n",
    "- 파이썬 dtaetime 자료형은 toordinal(투오디널) 명령으로 특정 시점으로부터 경과한 시간의 일단위 값을 구하거나 timestamp 메서드로 초단위 값을 구할 수 있다.\n",
    "    - 투오디널 명령은 1970년 1월1일을 기준으로 지금 며칠이 흘렀는지 계산\n",
    "- 시간 값의 경우 크기가 크므로 반드시 스케일링을 해줘야 한다. 시간만 아니고 항상 스케일링 하는 것을 습관화\n",
    "    - model5 = sm.OLS.from_formula(\"Demand ~ scale(Ordinal)\", data = df_elec)\n",
    "    - result5 = model5.fit()\n",
    "    - print(result5.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-19T08:32:15.135205Z",
     "start_time": "2020-05-19T08:32:15.124978Z"
    }
   },
   "source": [
    "#### 날짜가 독립변수로 들어가게 되면 그 날짜를 timestamp로 쓰는 것은 가장 기본적인 것\n",
    "- 거기에 카테고리 특징 값을 갖다가 뽑아내서 추가로 임베딩해서 쓰게 되면 성능이 나아지는 경우도 있다는 것\n",
    "- 오디널로 잡아내지 못하는 것을 시간, 일 등 카테고리 값으로 집어넣어서 비선형을 추가해 성분석해주면 성능이 좋아짐\n",
    "    - df_elec[\"Year\"] = df_elec.Date.dt.year\n",
    "    - df_elec[\"Month\"] =  df_elec.Date.dt.month\n",
    "    - df_elec[\"Day of Year\"] = df_elec.Date.dt.dayofyear\n",
    "    - dayofmonth, dayofweek(무슨 요일), weekofyear, weekday, is_month_start, is_month_end, 몇번째 주 안에 분기 정보도 들어가 있다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- aspect를 일반 실수형 독립변수처럼 사용하면 aspect가 0도일 때와 360도일 때 다른 종속변수값이 예측된다\n",
    "- 이를 방지하기 위해 일반적으로 주기성을 띄는 독립변수는 cos과 sin 두 개의 독립변수로 분리한다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 종속변수 변형\n",
    "- 지금까지는 독립변수를 변형하는 방법을 사용, 경우에 따라서는 종속변수 변형할 수 있다\n",
    "    - 제곱근, 로그 등 스캐터플롯을 그렸을 때 가능한한 직선이 되게 만드는 y의 변형을 쓰는 것도 하나의 트릭(제곱근보다 로그 취했을 때 성능이 더 좋음)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-19T08:43:28.069291Z",
     "start_time": "2020-05-19T08:43:28.064793Z"
    }
   },
   "source": [
    "#### 독립변수와 종속변수 모두에 로그를 취해줬을 때 제일 성능이 좋아지게 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-19T08:46:33.806296Z",
     "start_time": "2020-05-19T08:46:33.700720Z"
    }
   },
   "source": [
    "### summary: 많이 쓰는 트릭\n",
    "- 비선형인 경우 제곱 세제곱 로그 이런 것을 자꾸 추가 시켜줘야 한다\n",
    "- 시간데이터에서 다른 특징들 요일, 월, 주라든가 이런 것을 카테고리 값으로 집어넣어서 비선형성을 갖다가 추가시켜줄수 있다. 패턴의 모양을 추가해줄 수 있다\n",
    "- 주기성이 있을 때는 sin, cos로 바꿔줘야 한다\n",
    "- y와 yhat 데이터의 스캐터플롯 있을 때는 이를 직선으로 만들어줄수 있도록 y값 자체를 갖다가 변형시키는 것도 하나의 방법이다\n",
    "\n",
    "- 이런식으로 다양하게 모델 변형시켜서 성능 비교해볼 것"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.2 기저함수 모형과 과최적화\n",
    "- 기본적인 선형회귀모형은 입력 변수의 선형조합으로 이뤄진다\n",
    "- 하지만 데이터가 비선형이면 위와 같은 선형회귀모형은 적합하지 않다\n",
    "- 이럴 때 x를 입력으로 가지지 않고 x를 어떤 함수에 집어넣어서 변형을 시킨다\n",
    "- 이 x를 실제 x인 것처럼 가짜 x(파이)를 만드는 것\n",
    "- 그러면 파이에 대해서는 분명 선형회귀 모델, x값에 대해서는 비선형\n",
    "- 선형 모델방법론은 그대로 쓰면서 x에 대한 비선형 회귀를 할 수 있는 것\n",
    "- 파이에 뭘 넣을지를 우리가 고민해야"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 기저함수\n",
    "- 비선형 모형을 만들기 위해서는 데이터에 적합한 비선형 함수를 충분히 많이 생각해낼 수 있어야 한다\n",
    "- 기저함수는 특정한 규칙에 따라 만들어지는 함수의 열(sequence)로서 충분히 많은 수의 함수가 있으면 어떤 모양의 함수라도 비슷하게 흉내낼 수 있는 것을 말한다\n",
    "    - 이미 만들어져 있다. 갖다가 쓰기만 하면 된다\n",
    "    - 많이 쓰면 많이 쓸수록 점점 더 복잡한 비선형함수를 쓸 수 있게 된다\n",
    "- 기저함수 중 가장 간단한 것이 다항 기저함수(polynominal basis function)\n",
    "    - 다항회귀(polynominal regression)는 다항 기저함수를 사용하는 기저함수 모형.\n",
    "    - 체비세프 다항 기저함수, 방사 기저함수, 삼각 기저함수, 시그모이드 기저함수 등이 있다. 가장 많이 쓰는 것은 다항 기저함수 제일 쉬우니까\n",
    "- 기저함수는 사람이 하나씩 생각해내는 것이 아니라 미리 만들어진 규칙에 의해 자동으로 생성되므로 비선형 함수를 만들기 위해 고민할 필요가 없다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-19T09:02:59.385985Z",
     "start_time": "2020-05-19T09:02:59.377685Z"
    }
   },
   "source": [
    "### 과최적화(overfitting)\n",
    "- 모형을 특정 샘플 데이터에 대해 과도하게 최적화하는 것\n",
    "    - 독립변수 데이터 개수에 비해 모형 모수의 수가 과도하게 크거나\n",
    "    - 독립변수 데이터가 서로 독립이 아닌 경우에 발생(다중공선성)\n",
    "- 이런 상황에서는 같은 조건에 대해 답이 복수개 존재할 수 있기 때문"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-19T09:07:41.259579Z",
     "start_time": "2020-05-19T09:07:41.193007Z"
    }
   },
   "source": [
    "- 과최적화가 문제가 되는 이유는 다음과 같다\n",
    "    - 트레이닝에 사용되지 않은 새로운 독립 변수 값을 입력하면 오차가 커진다(cross-validation 오차)\n",
    "    - 샘플이 조금만 변화해도 가중치 계수의 값이 크게 달라진다(추정의 부정확하다는 뜻)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 과최적화를 어떻게 하면 막을 수 있는가?\n",
    "    - 1) 과최적화가 발생했는지의 여부 체크(교차 검증)\n",
    "    - 2) 발생했을 때 발생하지 않도록 막을 수 있는 방법은?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-19T09:12:40.849166Z",
     "start_time": "2020-05-19T09:12:40.838341Z"
    }
   },
   "source": [
    "# 6.3 교차검증\n",
    "#### 표본 내 성능과 표본 외 성능\n",
    "- 회귀 분석 모형을 마들기 위해서는 모수 추정 즉 학습(training)을 위한 데이터 집합이 필요하다\n",
    "- 이 데이터 집합을 학습용 데이터 집합(training data set)이라고 한다.\n",
    "- 이 학습 데이터 집합의 종속변수값을 얼마나 잘 예측하였는지를 나타내는 성능을 표본 내 성능 검증(in-sample testing)이라고 한다\n",
    "- 그런데 회귀분석 모형을 만드는 목적 중 하나는 종속변수의 값을 아직 알지 못하고 따라서 학습에 사용하지 않은 표본에 대해 종속 변수의 값을 알아내고자 하는 것 즉 예측(prediction)이다\n",
    "- 이렇게 학습에 쓰이지 않는 표본 데이터 집합의 종속 변수 값을 얼마나 잘 예측하는가를 검사하는 것을 표본 외 성능 검증(out-of-sample testing) 혹은 교차검증(cross validation)이라고 한다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 회귀분석이나 예측을 했을 때 성능을 알아볼 때는 인샘플 데이터의 경우 의미가 없다. 과최적화가 돼 있을 수 있기 때문에\n",
    "- 아웃오브 데이터가 중요. 검증할 때는 인샘플 데이터가 아닌 아웃오브 데이터로 검증해야 한다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 과최적화\n",
    "- 일반적으로 표본 내 성능과 표본 외 성능은 비슷한 수준을 보이지만 경우에 따라서는 표본 내 성능은 좋으면서 표본 외 성능이 상대적으로 많이 떨어지는 수도 있다. 이 경우 과최적화라고 한다\n",
    "- 과최적화가 발생하면 학습에 쓰였던 표본 데이터에 대해서는 종속변수의 값을 잘 추정하지만 새로운 데이터를 주었을 때 전혀 예측하지 못하기 떄문에 예측 목적으로 쓸모없는 모형이 되는 것\n",
    "- 이러한 과최적화가 발생하는 원인과 과최적화를 방지하기 위한 정규화(regularization) 방법은 다음 절에서.\n",
    "- 여기에서는 과최적화가 발생한 것을 탐자힉 위한 교차검증 방법을 공부"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-19T09:23:52.303042Z",
     "start_time": "2020-05-19T09:23:52.293337Z"
    }
   },
   "source": [
    "### 검증용 데이터 집합\n",
    "- 교차검증을 하려면 두 종류의 데이터 집합 필요\n",
    "    - 모형 추정 즉 학습을 위한 데이터 집합(training data set)\n",
    "    - 성능 검증을 위한 데이터 집합(test data set)\n",
    "- 두개의 데이터집합 모두 종속변수 값이 있어야 한다.\n",
    "- 따라서 보통은 가지고 있는 데이터 집합을 학습용과 검증용으로 나눈다\n",
    "- 학습용 데이터만을 사용해 회귀분석 모형을 만들고 검증용 데이터로 성능을 계산하는 학습/검증 데이터 분리(train-test split) 방법을 사용한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-19T09:27:10.787013Z",
     "start_time": "2020-05-19T09:27:10.782318Z"
    }
   },
   "outputs": [],
   "source": [
    "# choice 명령어 활용한 학습검증 데이터 분리 방법\n",
    "# N = len(df)\n",
    "# ratio = 0.7\n",
    "# np.random.seed(0)\n",
    "# idx_train = np.random.choice(np.arange(N), np.int(ratio * N))\n",
    "# idx_test = list(set(np.arange(N).difference(idx_train))\n",
    "\n",
    "# df_train = df.iloc[idx_train]\n",
    "# df_test = df.iloc[idx_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 우선 트레인 데이터를 이용해 OLS 회귀분석 방법으로 예측 모델을 만든 뒤\n",
    "- 테스트 데이터로 r-squared를 구할 때는 OLS 명령어 쓰면 안 됨. 다시 한번 학습하는 게 되기 때문\n",
    "- r-squared 구하는 공식을 직접 써야 한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-19T09:32:26.053702Z",
     "start_time": "2020-05-19T09:32:25.972482Z"
    }
   },
   "outputs": [],
   "source": [
    "# pred = result.predict(df_test)\n",
    "# rss = ((df_test.MEDV - pred) ** 2).sum()\n",
    "# tss = ((df_test.MEDV - df_test.MEDV.mean()) ** 2).sum()\n",
    "# rsquared = 1 - rss / tss\n",
    "# rsquared"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-19T09:34:44.465472Z",
     "start_time": "2020-05-19T09:34:44.459816Z"
    }
   },
   "source": [
    "### scikit-learn의 교차검증 기능\n",
    "- model_selection 서브 패키지\n",
    "#### 단순 데이터 분리\n",
    "- train_test_split 명령"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-폴드 교차검증(K-fold cross validation)\n",
    "- 데이터 수가 적은 경우에는 이 데이터 중의 일부인 검증 데이터의 수도 적기 때문에 검증 성능의 신뢰도가 떨어진다\n",
    "- 테스트를 여러번 해보면 된다. 자르는 방법을 달리해서"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-19T09:43:39.080278Z",
     "start_time": "2020-05-19T09:43:39.075198Z"
    }
   },
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import KFold\n",
    "# cv = KFold(5, shuffle=True, random_state=0) # 섞은 다음에 다섯 조각으로 만든다\n",
    "# for i, (idx_train, idx_test) in enumerate(cv.split(Df)): # split은 인덱스 넘버를 만들어주는 명령어\n",
    "#     df_train = df.iloc[idx_train]\n",
    "#     df_test = df.iloc[idx_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 대부분의 경우 학습용 데이터로 한 것보다 테스트 데이터로 한 결과가 조금 더 낮게 나온다\n",
    "- 최종적으로 데이터 쓸 때는 다 쓰는 게 맞다. 다 써서 만든 모델의 성능이 맞는 성능인가는 교차검증을 통해서 나온 값을 봐야 한다는 것"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 평가 점수\n",
    "- 사이킷런의 metrics 서브 패키지, 예측 성능 평가 위한 다양한 함수 제공\n",
    "- r2_score: 결정 계수\n",
    "- mean_squared_error : 평균 제곱 오차(mean squared error), RSS를 나누기 한 값?\n",
    "- median_absolute_error : 절대 오차 중앙값(median abolute error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 벤치마크 검증 데이터 \n",
    "- 유명한 벤치마크 문제나 캐글 같은 데이터분석 경진대회에서는 최종 성능검증을 위한 검증 데이터가 별도로 제공될 수도 있다\n",
    "- 어떤 K폴드 등의 방법으로 생성된 검증 데이터가 달라지면 성능도 약간씩 달라질 수 있기 때문에\n",
    "- 따라서 이렇게 유일한 검증 데이터에 대한 성능은 엄격한 의미에서 절대적인 것이라고 볼 수 없다\n",
    "- 이러한 경우에도 학습용 데이터를 K폴드 등의 방법으로 나눠 교차검증을 실시함으로써 과최적화를 막을 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
